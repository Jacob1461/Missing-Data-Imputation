```{r, include=FALSE, warning=FALSE}
library(bookdown)
library(dplyr)
library(knitr)
library(kableExtra)
```


# Illustration of the method application


Using the methods of missing data in practice.

## The data \label{section:the_data}

### Sunspots

The sunspots datasert reports the monthly mean relative sunspot numbers from 1749 to 1983 [@sunspots_Dataset]. There are 2820 observations.  

### Lake Huron

This dataset reports the annual level of Lake Huron (located in Canada and the United States) measured in feet [@LakeHuron_Dataset]. There are 98 observations in the dataset.  

### Beer Sales  

This dataset reports the monthly beer sales from 1975 to 1990 in millions of barrels [@Beersales_Dataset]. There are 192 observations.  

### Lynx

This dataset records the number of Lynx that are trapped at the Mackenize River district in Canada from 1821 to 1934 [@Lynx_Dataset1; @Lynx_Dataset2; @Lynx_Dataset3]  


### Stock Market Prediction
The data used for multivariate imputation was a subset of CNN data on [kaggle](https://www.kaggle.com/datasets/ehoseinz/cnnpred-stock-market-prediction). This subset was NASDAQ data comprising of features from various categories of technical indication. There are 81 variables, from those, there are 80 variables with missingness, within those 80 variables, there is a cumulative percentage of 1.88% missing data. $n=1984$ is the number of values that need imputing. There are $105531$ data-points in total. Let it be known that we do not have the ground truths for the original data.

## The methods

### Univariate

From the R package missMethods the function delete_MCAR is used to generate MCAR missingess. For each univariate dataset mention in Section \ref{section:the_data} seven datasets are generated with varying degrees of missingness from $10\%$ to $70\%$. With each time series of missing data each of the data imputation methods introduced in Section \ref{Section:univariateimputation} since the true series is known the root mean squared error $RMSE = \sqrt{\sum_{i=1}^n \frac{(y-\hat{y})}{n}}$. The RMSE is not calculated for missing values. The RMSE values are provided in \ref{fig:Univarite_comparison}. Since there is randomness involved with the generation of missing data each test was performed 10 times with different seeds, the RMSE values where then averaged. The table of RMSE values can be found in Table \ref{tab:RMSE_sunspots}

### MICE

We run MICE imputation for 25 iterations, or to convergence, whatever happened first, as there was a large amount of data in the NASDAQ dataset. Convergence is essential when imputing with MICE so the high level of iterations meant we could reach convergence. In practice, 10 is typically used. Although that would commonly be seen on a much smaller dataset.

### GAN

We train the GAN on the features of the NASDAQ data. Training was conducted for 1500 epochs with mini batch sizes of 128.

In each epoch:

-   A batch of real data is selected, which passes through the generator to generate synthetic data.

-   The discriminator is trained using real and synthetic values, it receives real labels for the real data and receives fake labels for the synthetic data.

-   After training the discriminator, the generator is optimised to minimise the adversarial loss (fool our discriminator). And reconstruction loss (ensure the generated data is resembling our generated data).

Our hyper parameters for the model was *hidden_size=128, latent_size=256, epochs=1500, batch_size=128*.

### Quality of results  

#### Univariate



#### Multivariate
After imputation, we use Kernel Density Estimation to estimate the true distribution for the variables in our data, as well as our imputation methods. KDE provides a smooth estimation for the true distribution.

The Kullback-Leibler (KL) divergence is used to measure the difference between the distributions of our imputed data (GAN and MICE) against our original data (with missingness). Since the ground truth for our original data is not known, this comparison helps us asses how well our imputation methods match the inferred distribution of our original data.

The KL Divergence is calculated for each variable, and each method that went through imputation. We then take the mean over all the variables for each method to get an overall average and assessment of how well our imputation methods work.

```{r, echo=FALSE, warning=FALSE}
kl_metrics <- read.csv("../metrics/kl_divergence_metrics.csv")
kl_metrics %>% head() %>% 
  kable(caption = "KL Divergence Metrics")
```

By doing this, we can try and gain an understanding into how well our methods have worked while having the absence of ground truths in our data.

```{r times-table, echo=FALSE, warning=FALSE}

times <- read.csv("../metrics/times_multivariate.csv")


kable(times, caption = "Imputation Method Times")

```

From **Table 3.2**, we can see that MICE was the quickest method out of the two. It almost took half the time to train as the GAN. 

```{r, echo=FALSE, warning=FALSE}

kl_means <- read.csv("../metrics/mean_kl_divergence.csv")



kable(kl_means, caption = "Mean KL Divergence Means")

```

Overall, MICE provided us with the best results in the quickest period of times. 
**Table3.3** summarises the mean KL divergence for each method. Further training and hyper parameter training of the GAN could yield better results but that would need to be conducted in further research. 


```{r child='chapter3_content/univariate_figs.Rmd'}
```

